{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bb77e8",
   "metadata": {},
   "source": [
    "# Simple Hugging Face TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1217a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# import torch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from transformers import CsmForConditionalGeneration, AutoProcessor\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from huggingface_hub import snapshot_download\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# # 4. Save as WAV\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# torchaudio.save(\"output.wav\", audio.unsqueeze(0).cpu(), processor.feature_extractor.sampling_rate)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcsm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_csm_1b\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchaudio\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Apziva Projects/Project 4/Mon-Reader/csm/generator.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchaudio\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmoshi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m loaders\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtokenizers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TemplateProcessing\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "\n",
    "# import torch\n",
    "# from transformers import CsmForConditionalGeneration, AutoProcessor\n",
    "# from huggingface_hub import snapshot_download\n",
    "# import torchaudio\n",
    "# import os\n",
    "\n",
    "# # Option 1: Pre-download model for offline use\n",
    "# # Uncomment to download model ahead of time for offline/firewalled environments\n",
    "# # snapshot_download(repo_id=\"sesame/csm-1b\", repo_type=\"model\")\n",
    "\n",
    "# # Option 2: Set environment variable for offline usage\n",
    "# # os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "\n",
    "# # 1. Model & processor\n",
    "# model_id = \"sesame/csm-1b\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Option 3: Use local_files_only=True for cached/offline models\n",
    "# processor = AutoProcessor.from_pretrained(model_id)  # Add local_files_only=True if using cached model\n",
    "# model = CsmForConditionalGeneration.from_pretrained(model_id, device_map=device)  # Add local_files_only=True if using cached model\n",
    "\n",
    "# # 2. Prepare input text (speaker id 0)\n",
    "# text = \"[0]Hello from Sesame!\"\n",
    "# inputs = processor(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# # 3. Synthesize audio\n",
    "# audio = model.generate(**inputs, output_audio=True)\n",
    "\n",
    "# # 4. Save as WAV\n",
    "# torchaudio.save(\"output.wav\", audio.unsqueeze(0).cpu(), processor.feature_extractor.sampling_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4aeb3",
   "metadata": {},
   "source": [
    "# Eleven Labs Streaming Audio Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4790750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import stream\n",
    "from elevenlabs.client import ElevenLabs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "key = os.getenv('ELEVEN_LABS_KEY')\n",
    "client = ElevenLabs(api_key=key)\n",
    "audio_stream = client.text_to_speech.stream(\n",
    "    #text=\"This is a test\",\n",
    "    text = '''★ شادی شدہ کی موت پر دوسرے کی شادی کرنا ۔ (عدت کے بعد)\n",
    "★ شوہر اپنی عورت کا جنازہ پڑھائے ۔\n",
    "★ عورت کی میت کو غیر مرد ہاتھ لگائے ۔ (عدت کے اندر بھی)\n",
    "★ زنا کاری ۔ بے غیرتی ۔ خود غرضی ۔ چوری ۔ سود ۔ حرام ۔\n",
    "★ زنا کاری کی سزا ۔ (عورت کا سر مونڈنا، پتھر مار مار کر ہلاک کرنا ۔) (مسلم)\n",
    "\n",
    "  ''',\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    model_id=\"eleven_multilingual_v2\"\n",
    ")\n",
    "\n",
    "# option 1: play the streamed audio locally\n",
    "stream(audio_stream)\n",
    "\n",
    "# option 2: process the audio bytes manually\n",
    "for chunk in audio_stream:\n",
    "    if isinstance(chunk, bytes):\n",
    "        print(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee3319",
   "metadata": {},
   "source": [
    "# Eleven Labs TTS on OCR Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d064561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 text files to process\n",
      "\n",
      "============================================================\n",
      "PROCESSING FILE: textbook_img.txt\n",
      "============================================================\n",
      "TEXT CONTENT:\n",
      "The text in the image reads:\n",
      "\n",
      "\"Episode 25: When the Moon Splits\n",
      "\n",
      "Synopsis:\n",
      "\n",
      "The war for Ryloth rages on, as Mon Calamari rebels are forced to confront the reality of their situation.\n",
      "\n",
      "In the midst of the battle, Chancellor Lando Calrissian must decide whether to continue with his risky plan or abandon it. The fate of the moon hangs in the balance.\n",
      "\n",
      "The crew of the Ghost, led by a reluctant Hera Syndulla, uncovers an unexpected ally in their quest for victory. But can they trust this newcomer?\n",
      "\n",
      "Meanwhile, Sabine's skills as a weapons smith are put to the test as she attempts to repair the damage done during the battle.\n",
      "\n",
      "As the moon splits, Hera must lead her team through a gauntlet of challenges in order to save their home and loved ones.\n",
      "\n",
      "Will they be able to overcome their fears and save Ryloth? Or will it slip into darkness forever?\n",
      "\n",
      "The fate of the moon and its inhabitants rests in the hands of the Ghost crew.\"\n",
      "============================================================\n",
      "\n",
      "Converting: extracted_text/ollama_direct/textbook_img.txt -> tts_outputs/textbook_img.mp3\n",
      "Error processing extracted_text/ollama_direct/textbook_img.txt: headers: {'date': 'Thu, 17 Jul 2025 20:33:26 GMT', 'server': 'uvicorn', 'content-length': '173', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': '0aae1fbb13d1b717313c3801f78eef24', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 606 credits remaining, while 927 credits are required for this request.'}}\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "PROCESSING FILE: IMG_20250629_214324_528.txt\n",
      "============================================================\n",
      "TEXT CONTENT:\n",
      "The image shows a page with handwritten notes, and it appears to be a personal study or workbook. Here's the extracted text:\n",
      "\n",
      "```\n",
      "TASK\n",
      "\n",
      "1. Read chapter 6\n",
      "2. Practice exercises 6.1 & 6.2\n",
      "3. Write report on topic of chapter 6\n",
      "4. Discuss with classmates\n",
      "5. Hand in by Friday\n",
      "```\n",
      "\n",
      "Please note that the handwriting quality is not ideal, and some words are more accurate than others due to the writing style. If you need a clearer version of this text or have any questions about the extracted text, feel free to ask!\n",
      "============================================================\n",
      "\n",
      "Converting: extracted_text/ollama_direct/IMG_20250629_214324_528.txt -> tts_outputs/IMG_20250629_214324_528.mp3\n",
      "Audio saved: tts_outputs/IMG_20250629_214324_528.mp3\n",
      "Playing audio: IMG_20250629_214324_528.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# Process all text files in ollama_direct folder\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[43mprocess_ollama_direct_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll files processed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mprocess_ollama_direct_folder\u001b[39m\u001b[34m(folder_path, output_dir)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Process each text file\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m txt_file \u001b[38;5;129;01min\u001b[39;00m txt_files:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[43mconvert_text_to_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mconvert_text_to_audio\u001b[39m\u001b[34m(text_file_path, output_dir)\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m audio_chunks:\n\u001b[32m     65\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished playing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Apziva Projects/Project 4/Mon-Reader/env/lib/python3.12/site-packages/elevenlabs/play.py:91\u001b[39m, in \u001b[36mstream\u001b[39m\u001b[34m(audio_stream)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     90\u001b[39m         mpv_process.stdin.write(chunk)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m         \u001b[43mmpv_process\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     92\u001b[39m         audio += chunk\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpv_process.stdin:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from elevenlabs import stream\n",
    "from elevenlabs.client import ElevenLabs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "key = os.getenv('ELEVEN_LABS_KEY')\n",
    "client = ElevenLabs(api_key=key)\n",
    "\n",
    "def convert_text_to_audio(text_file_path, output_dir=\"tts_outputs\"):\n",
    "    \"\"\"\n",
    "    Convert a text file to audio and save it\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the text file\n",
    "        with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "        \n",
    "        if not text_content.strip():\n",
    "            print(f\"Skipping empty file: {text_file_path}\")\n",
    "            return\n",
    "        \n",
    "        # Print the text content being processed\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FILE: {Path(text_file_path).name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"TEXT CONTENT:\\n{text_content}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Generate audio filename\n",
    "        text_filename = Path(text_file_path).stem\n",
    "        audio_filename = f\"{text_filename}.mp3\"\n",
    "        audio_path = os.path.join(output_dir, audio_filename)\n",
    "        \n",
    "        print(f\"Converting: {text_file_path} -> {audio_path}\")\n",
    "        \n",
    "        # Generate audio stream\n",
    "        audio_stream = client.text_to_speech.stream(\n",
    "            text=text_content,\n",
    "            voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "            model_id=\"eleven_multilingual_v2\"\n",
    "        )\n",
    "        \n",
    "        # Save audio to file and collect chunks for streaming\n",
    "        audio_chunks = []\n",
    "        with open(audio_path, 'wb') as audio_file:\n",
    "            for chunk in audio_stream:\n",
    "                if isinstance(chunk, bytes):\n",
    "                    audio_file.write(chunk)\n",
    "                    audio_chunks.append(chunk)\n",
    "        \n",
    "        print(f\"Audio saved: {audio_path}\")\n",
    "        \n",
    "        # Play the audio aloud\n",
    "        print(f\"Playing audio: {audio_filename}\")\n",
    "        try:\n",
    "            # Create a generator from the collected chunks to stream\n",
    "            def audio_generator():\n",
    "                for chunk in audio_chunks:\n",
    "                    yield chunk\n",
    "            \n",
    "            stream(audio_generator())\n",
    "            print(f\"Finished playing: {audio_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing audio {audio_filename}: {str(e)}\")\n",
    "            # Fallback: try to play from saved file\n",
    "            try:\n",
    "                with open(audio_path, 'rb') as audio_file:\n",
    "                    audio_data = audio_file.read()\n",
    "                    stream(audio_data)\n",
    "                print(f\"Finished playing (fallback): {audio_filename}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"Fallback audio playback also failed for {audio_filename}: {str(e2)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {text_file_path}: {str(e)}\")\n",
    "\n",
    "def process_ollama_direct_folder(folder_path=\"extracted_text/ollama_direct\", output_dir=\"tts_outputs\"):\n",
    "    \"\"\"\n",
    "    Process all text files in the ollama_direct folder\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    if not folder_path.exists():\n",
    "        print(f\"Folder {folder_path} does not exist!\")\n",
    "        return\n",
    "    \n",
    "    # Find all .txt files in the folder\n",
    "    txt_files = list(folder_path.glob(\"*.txt\"))\n",
    "    \n",
    "    if not txt_files:\n",
    "        print(f\"No .txt files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(txt_files)} text files to process\")\n",
    "    \n",
    "    # Process each text file\n",
    "    for txt_file in txt_files:\n",
    "        convert_text_to_audio(txt_file, output_dir)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Process all text files in ollama_direct folder\n",
    "    process_ollama_direct_folder()\n",
    "    \n",
    "    print(\"All files processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
